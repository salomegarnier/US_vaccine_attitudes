---
title: "Modeling"
author: "Salom√© Garnier, Simone Lewis, Neha Gupta, Corbin Duncan, Connor Brown"
date: "4/9/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#load packages
library(tidyverse)
library(pROC)
library(glmnet)
library(readr)
library(MASS)
library(ggplot2)

#load dataset
demographics <- read_csv("demographics_id.csv")
```

Connor: I went back into the .csv and added an id column (I'll upload to Git) which allowed me to split using random sampling between training and testing data. 

```{r test and train}
#split demographics voter data into training and test set using sampling
#Set seed for replication
set.seed(02138)

## For Regression analysis
#allocated 75% of data to training and 25% of data to testing
row.number <- sample(1:nrow(demographics), 0.75 * nrow(demographics))
n_train = demographics[row.number,]
n_test = demographics[-row.number,]

#summarise
dim(n_train)
dim(n_test)
```
Connor: Here I fitted a logistic regression model on the predictor (X) demographic variables of gender, age, education, race, and financial status. Intention to take up the covid vaccine based on the survey results is the outcome variable (Y). From looking at the model output, education level and financial status are significant at the p < 0.05 level; there is a positive relationship. Age is also slightly significant at the 0.10 level, again there is a positive relationship. 

```{r fit model}
## USA Model
#fit the demographic variables onto the outcome variable of vaccine acceptance

#model 1 exclude flu_shot
fm1 <- covid_vaccine ~ gender + age_group + education + race + financial_status

#model 2 include flu shot
fm2 <- covid_vaccine ~ gender + age_group + education + race + financial_status + flu_shot

#estimate model 1 (logistic regression)
model1 <- glm(fm1, data = n_train, family = "binomial", na.action = na.exclude)
summary(model1)

#estimate model 2 (logistic regression)
model2 <- glm(fm2, data = n_train, family = "binomial", na.action = na.exclude)
summary(model2)

#report collinearity of vaccines
cor(demographics$covid_vaccine, demographics$flu_shot, use = "complete.obs")

```

```{r prediction outcomes}
#Calculate prediction value on the test set
yhat_test <- predict(model1, newdata = n_test, "response")

#Plot prediction value density of test set
hist(yhat_test, freq = FALSE, xlim = c(0, 1), ylim = c(0, 6))

#Create yhat column on the country level model
demographics$yhat <- predict(model1, newdata = demographics, "response")
```

```{r roc curve}
#Compute ROC curve 
dem.roc1 <- roc(
  response  = n_test$covid_vaccine,
  predictor = yhat_test
)

#Plot ROC curve
plot(dem.roc1, 
     xlab = "False Positive Rate or 1-Specificity",
     ylab = "True Positive Rate or Sensitivity",
     main = "ROC Curve (Our Model)",
     legacy.axes = TRUE)

#Calculate AUC = 0.703, chance a positive case outranks a negative case. 
auc(dem.roc1)
```

```{r threshold and model accuracy}
#Calculate the threshold for positive case from test set
threshold <- coords(dem.roc1, x = "best", transpose = TRUE,
                      ret = c("threshold","accuracy","precision","recall"))

#Report efficiency table of model
knitr::kable(rbind(threshold), row.names = FALSE, digits = 3)

n_test$threshold <- threshold[1]

#Calculate f-score = 0.735
f1 <- 2*((0.91*0.617)/(0.91+0.617))
f1

#Use boolean logic to determine model v. actual prediction value
n_test$yhat_actual <- as.numeric(yhat_test >= n_test$threshold)

#Create prop table of model efficiency
prop_table_covid <- prop.table(table(n_test$yhat_actual, n_test$covid_vaccine))
rownames(prop_table_covid) <- c("Deny Vaccine (True)", "Seek Vaccine (True)")
colnames(prop_table_covid) <- c("Deny Vaccine (Predicted)", "Seek Vaccine (Predicted)")
prop_table_covid

##False negative rate is 0.312 (top right), the false positive rate is 0.0496 (bottom left)

```
